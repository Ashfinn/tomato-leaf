# ğŸ… A Comparative Analysis of Deep and Traditional Learning Models for Tomato Leaf Disease Classification

## ğŸ”¬ Project Overview

**TomatoNet** is a research project that compares the performance of traditional **Machine Learning (ML)** models and modern **Deep Learning (DL)** architectures in classifying tomato leaf diseases. With a focus on agricultural AI, this work explores how different models behave on real-world data, including the impact of background removal on performance.

---

## ğŸ“ Directory Structure

```

TOMATO-LEAF/
â”‚
â”œâ”€â”€ dataset/                        # Original dataset with disease folders
â”œâ”€â”€ tomato\_bg\_removed/             # Background-removed version of dataset
â”œâ”€â”€ models/                        # Saved DL models (.h5 files)
â”‚   â”œâ”€â”€ best\_inceptionv3.h5
â”‚   â””â”€â”€ xception\_tomato\_leaf\_model.h5
â”œâ”€â”€ metrics and visualizations/    # Evaluation visuals
â”‚   â”œâ”€â”€ confusion\_matrix.png
â”‚   â”œâ”€â”€ inception\_confusion\_matrix.png
â”‚   â”œâ”€â”€ inception\_training\_metrics.png
â”‚   â””â”€â”€ training\_history.png
â”œâ”€â”€ notebooks/                     # All model training notebooks
â”‚   â”œâ”€â”€ bg\_removed\_inception.ipynb
â”‚   â”œâ”€â”€ EfficientB1.ipynb
â”‚   â”œâ”€â”€ inception.ipynb
â”‚   â”œâ”€â”€ KNN+NB+XGBoost.ipynb
â”‚   â”œâ”€â”€ Mobile\_shuffle\_efficient.ipynb
â”‚   â””â”€â”€ Xception.ipynb
â””â”€â”€ readme.md                      # Project documentation

````

---

## ğŸ“Š Dataset Details

- **Source:** Custom-collected dataset of tomato leaf images.
- **Classes:**
  - Tomato__Target_Spot  
  - Tomato__Tomato_mosaic_virus  
  - Tomato__Tomato_YellowLeaf__Curl_Virus  
  - Tomato_Bacterial_spot  
  - Tomato_Early_blight  
  - Tomato_healthy  
  - Tomato_Late_blight  
  - Tomato_Leaf_Mold  
  - Tomato_Septoria_leaf_spot  
  - Tomato_Spider_mites_Two_spotted_spider_mite

- **Dataset Variants:**
  - **Original dataset**
  - **Background-removed dataset** (via preprocessing)

---

## ğŸ¤– Models Compared

### ğŸ”· Machine Learning Models
Implemented in `KNN+NB+XGBoost.ipynb`:
- K-Nearest Neighbors (KNN)
- Naive Bayes (NB)
- XGBoost

> Features were extracted using pre-trained CNNs or hand-crafted descriptors.

---

### ğŸ”¶ Deep Learning Models

| Model             | Notebook                         | Accuracy (%) | Notes                         |
|------------------|----------------------------------|--------------|-------------------------------|
| **Xception**      | `Xception.ipynb`                 | **97.00**    | Best performing overall       |
| EfficientNetB0    | `EfficientB1.ipynb`              | 94.26        | Excellent efficiency-accuracy |
| MobileNetV2       | `Mobile_shuffle_efficient.ipynb` | 92.79        | Lightweight & fast            |
| ShuffleNetV2      | `Mobile_shuffle_efficient.ipynb` | 90.54        | Lightweight, less accurate    |
| InceptionV2       | `inception.ipynb`                | 83.00        | Underperformed in this task   |

---

## ğŸ“ˆ Evaluation Metrics

- **Accuracy**
- **Precision, Recall, F1-Score**
- **Confusion Matrix**
- **Training/Validation Curves**
- **Visuals** available in `metrics and visualizations/`

---

## âœ… Key Findings

- **Xception** gave the highest accuracy (97%), making it ideal for deployment.
- **EfficientNetB0** offered a good trade-off between speed and performance.
- **MobileNetV2** and **ShuffleNetV2** are suitable for resource-constrained environments.
- **InceptionV2** was less effective despite its complexity.
- Traditional ML models are faster to train but were outperformed by DL models.
- **Removing background** boosted model performance by eliminating irrelevant noise.

---

## ğŸ› ï¸ Installation & Setup

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/tomato-leaf-disease-classification
   cd tomato-leaf-disease-classification
````

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. Run any Jupyter notebook in `notebooks/`.

---

## ğŸš€ How to Use

1. Use `KNN+NB+XGBoost.ipynb` for classical ML models.
2. Use the respective `.ipynb` files for DL model training.
3. Pre-trained models are available in the `models/` folder.
4. Evaluate performance using visuals from `metrics and visualizations/`.

---

## ğŸ§  Future Scope

* Include attention-based architectures (e.g., Vision Transformers)
* Fine-tune models with real-world data augmentation
* Deploy top-performing model into a **web/mobile plant health app**
* Test the model on other plant species and diseases

---

## ğŸ‘¨â€ğŸ’» Author

**Obidur Rahman (Ashfin)**
ğŸ”— [YouTube](https://www.youtube.com/@ObidurRahman) | ğŸ’¬ Educator, ML Researcher & Content Creator
ğŸ§  Passionate about AI, education, and solving real-world problems with tech.

---

## ğŸ“œ License

This project is open-source under the [MIT License](LICENSE).

---

*Made with â¤ï¸ and a lot of tomato leaves!*

```
